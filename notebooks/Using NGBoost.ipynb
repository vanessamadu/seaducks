{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Multivariate Gaussian NGBoost (MVN NGBoost)\n",
    "\n",
    "This notebook outlines using MVN NGBoost for predicting response vectors for simulated and real world data. This notebook draws upon [O'Malley et al. 2023](https://www.cambridge.org/core/journals/environmental-data-science/article/probabilistic-prediction-of-oceanographic-velocities-with-multivariate-gaussian-natural-gradient-boosting/F26F2BD51213758208B0EBAE51D1A973#article) and the supplementary materials they have provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('models'), '..')))\n",
    "import pandas as pd\n",
    "import ngboost\n",
    "import numpy as np\n",
    "from seaducks.models._mvn_ngboost import MVN_ngboost\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Example\n",
    "\n",
    "In this example, following the work of O'Malley et al. (2023), we generate synthetic data according to: \n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf{X}_{i} & \\stackrel{\\text { IID }}{\\sim} \\text { Uniform }(0, \\pi) \\\\\n",
    "\\mathbf{Y}_{i} \\mid \\mathbf{X}_{i} & \\sim \\mathbb{N}\\left(\\left[\\begin{array}{l}\n",
    "\\mu_{1}\\left(\\mathbf{X}_{i}\\right) \\\\\n",
    "\\mu_{2}\\left(\\mathbf{X}_{i}\\right)\n",
    "\\end{array}\\right],\\left[\\begin{array}{cc}\n",
    "\\sigma_{1}^{2}\\left(\\mathbf{X}_{i}\\right) & \\sigma_{1}\\left(\\mathbf{X}_{i}\\right) \\sigma_{2}\\left(\\mathbf{X}_{i}\\right) \\rho\\left(\\mathbf{X}_{i}\\right) \\\\\n",
    "\\sigma_{1}\\left(\\mathbf{X}_{i}\\right) \\sigma_{2}\\left(\\mathbf{X}_{i}\\right) \\rho\\left(\\mathbf{X}_{i}\\right) & \\sigma_{2}^{2}\\left(\\mathbf{X}_{i}\\right),\n",
    "\\end{array}\\right]\\right)\n",
    "\\end{aligned}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{1}(x) & =\\sin (2.5 x) \\sin (1.5 x)+x, \\\\\n",
    "\\mu_{2}(x) & =\\cos (3.5 x) \\cos (0.5 x)-x^{2}, \\\\\n",
    "\\sigma_{1}^{2}(x) & =0.01+0.25[1-\\sin (2.5 x)]^{2}, \\\\\n",
    "\\sigma_{2}^{2}(x) & =0.01+0.25[1-\\cos (3.5 x)]^{2}, \\\\\n",
    "\\rho(x) & =\\sin (2.5 x) \\cos (0.5 x) .\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means(x,multiplier):\n",
    "    return multiplier*np.sin(2.5*x)*np.sin(1.5*x) + x, multiplier*np.cos(3.5*x)*np.cos(0.5*x) - x**2\n",
    "\n",
    "def variances(x,multiplier,additive):\n",
    "    return additive + multiplier*(1-np.sin(2.5*x))**2, additive + multiplier*(1-np.cos(3.5*x))**2\n",
    "\n",
    "def correlation(x):  \n",
    "    return np.sin(2.5*x)*np.cos(0.5*x)\n",
    "\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "def covariance_matrix(x, multiplier, additive):\n",
    "    var1,var2 = variances(x, multiplier, additive)\n",
    "    cov = correlation(x)*np.sqrt(var1*var2)\n",
    "    return [np.array([[var1_val, cov_val],[cov_val, var2_val]]) for var1_val, var2_val,cov_val in zip(var1,var2,cov)]\n",
    "\n",
    "def mean_vector(x, multiplier):\n",
    "    mean1,mean2 = means(x,multiplier)\n",
    "    return [np.array([val1,val2]) for val1,val2 in zip(mean1,mean2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(N, sort=False, multiplier = 0.25, additive = 0.01):\n",
    "    x = np.random.rand(N) * np.pi\n",
    "    if sort:\n",
    "        x = np.sort(x)\n",
    "    mean = mean_vector(x,multiplier=multiplier)\n",
    "    cov = covariance_matrix(x, multiplier=multiplier, additive=additive)\n",
    "    rvs = [stats.multivariate_normal(mean_val,cov_val).rvs(1) for mean_val,cov_val in zip(mean,cov)]\n",
    "\n",
    "    return rvs\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<scipy.stats._multivariate.multivariate_normal_frozen at 0x15b4f9f1640>,\n",
       " <scipy.stats._multivariate.multivariate_normal_frozen at 0x15b4f9f0cb0>,\n",
       " <scipy.stats._multivariate.multivariate_normal_frozen at 0x15b4f9f3b60>,\n",
       " <scipy.stats._multivariate.multivariate_normal_frozen at 0x15b4fa12540>,\n",
       " <scipy.stats._multivariate.multivariate_normal_frozen at 0x15b4f9fc470>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_data(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drifter Velocity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path_to_data = r'..\\seaducks\\data\\filtered_nao_drifters_with_sst_gradient.h5'\n",
    "data = pd.read_hdf(path_to_data)\n",
    "# add day of the year as an index (to be added to the data later)\n",
    "data['day_of_year'] = data['time'].apply(lambda t : t.timetuple().tm_yday)\n",
    "\n",
    "# separate into explanatory and response variables\n",
    "explanatory_var_labels = ['u_av','v_av','lat','lon','day_of_year','Wx','Wy','Tx','Ty','sst_x_derivative','sst_y_derivative']\n",
    "response_var_labels = ['u','v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_ngboost = MVN_ngboost(n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.0487 val_loss=-0.0734 scale=0.5000 norm=1.5439\n"
     ]
    }
   ],
   "source": [
    "file_name = 'test'\n",
    "multivariate_ngboost.run_model_and_save(data,explanatory_var_labels,response_var_labels,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('testtest_data.p', 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances for mu_x\n",
      "u_av: 0.9630686644026271\n",
      "v_av: 0.0\n",
      "lat: 0.010718825286130815\n",
      "lon: 0.0\n",
      "day_of_year: 0.0\n",
      "Wx: 0.0\n",
      "Wy: 0.0\n",
      "Tx: 0.0\n",
      "Ty: 0.0\n",
      "sst_x_derivative: 0.0\n",
      "sst_y_derivative: 0.026212510311242217\n",
      "\n",
      "Feature Importances for mu_y\n",
      "u_av: 0.0\n",
      "v_av: 0.9633852850700406\n",
      "lat: 0.0\n",
      "lon: 0.03661471492995927\n",
      "day_of_year: 0.0\n",
      "Wx: 0.0\n",
      "Wy: 0.0\n",
      "Tx: 0.0\n",
      "Ty: 0.0\n",
      "sst_x_derivative: 0.0\n",
      "sst_y_derivative: 0.0\n",
      "\n",
      "Feature Importances for a_11\n",
      "u_av: 0.8943763743919959\n",
      "v_av: 0.0\n",
      "lat: 0.05246232160479388\n",
      "lon: 0.01938576201026696\n",
      "day_of_year: 0.0\n",
      "Wx: 0.0\n",
      "Wy: 0.0\n",
      "Tx: 0.0\n",
      "Ty: 0.0\n",
      "sst_x_derivative: 0.0\n",
      "sst_y_derivative: 0.03377554199294332\n",
      "\n",
      "Feature Importances for a_12\n",
      "u_av: 0.09031625171022113\n",
      "v_av: 0.1437495608114901\n",
      "lat: 0.5364111320251134\n",
      "lon: 0.22363409628069744\n",
      "day_of_year: 0.0\n",
      "Wx: 0.0\n",
      "Wy: 0.0\n",
      "Tx: 0.0\n",
      "Ty: 0.0\n",
      "sst_x_derivative: 0.0035021544794677033\n",
      "sst_y_derivative: 0.002386804693010288\n",
      "\n",
      "Feature Importances for a_22\n",
      "u_av: 0.0\n",
      "v_av: 0.7402647521755785\n",
      "lat: 0.007575646575885427\n",
      "lon: 0.23271187075249303\n",
      "day_of_year: 0.0\n",
      "Wx: 0.0\n",
      "Wy: 0.0\n",
      "Tx: 0.0\n",
      "Ty: 0.0\n",
      "sst_x_derivative: 0.019447730496043047\n",
      "sst_y_derivative: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fi=multivariate_ngboost.feature_importances_\n",
    "params = ['mu_x', 'mu_y', 'a_11', 'a_12','a_22']\n",
    "\n",
    "for jj,param in enumerate(params):\n",
    "    print(f'\\nFeature Importances for {param}')\n",
    "    for ii, var in enumerate(explanatory_var_labels):\n",
    "        print(f\"{var}: {fi[jj][ii]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multivariate_ngboost.best_val_loss_itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngboost.NGBoost.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23671849794720257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted_distribution = content[1]\n",
    "true_values = content[0]\n",
    "locs, covs = predicted_distribution\n",
    "\n",
    "np.sqrt(np.mean(np.square(np.array(true_values)-locs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Cross-Validation, and Testing\n",
    "\n",
    "To do:\n",
    "* Explain what each of these terms mean and why we are doing them.\n",
    "* Decide on the train-test-cross validation split\n",
    "* Explain that this split must also apply for each drifter and explain why\n",
    "* Include a sketch implementation of how this might be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MVN NGBoost Model\n",
    "\n",
    "Include an explainer here as to how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explanatory_vars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m multivariate_ngboost \u001b[38;5;241m=\u001b[39m ngboost\u001b[38;5;241m.\u001b[39mNGBoost(Dist\u001b[38;5;241m=\u001b[39mngboost\u001b[38;5;241m.\u001b[39mdistns\u001b[38;5;241m.\u001b[39mMultivariateNormal(\u001b[38;5;241m2\u001b[39m),n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m multivariate_ngboost\u001b[38;5;241m.\u001b[39mfit(X \u001b[38;5;241m=\u001b[39m \u001b[43mexplanatory_vars\u001b[49m, Y \u001b[38;5;241m=\u001b[39m response_vars)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'explanatory_vars' is not defined"
     ]
    }
   ],
   "source": [
    "import ngboost.distns\n",
    "\n",
    "multivariate_ngboost = ngboost.NGBoost(Dist=ngboost.distns.MultivariateNormal(2),n_estimators=15)\n",
    "# fit the model\n",
    "multivariate_ngboost.fit(X = explanatory_vars, Y = response_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictive distribution for each \n",
    "predicted_distribution = multivariate_ngboost.pred_dist(explanatory_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23382208583662384"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "point_predictions = [point for point in predicted_distribution.loc]\n",
    "np.sqrt(np.mean(np.square(np.array(response_vars)-point_predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeaDucks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
