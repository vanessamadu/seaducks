{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Impact of Cluster Sampling on the Size of the Training, Testing, and Validation Sets\n",
    "\n",
    "When training the MVN NGBoost model on the drifter data, we must take eidstra care to ensure that information about the testing and validation sets is not inadvertedly introduced into the training data. The ~400,000 drifter observations that form our data set come from ~2000 unique drifters. We expect that observations taken by the same drifter are likely to be highly correlated so we ensure that all of the observations made by any single drifter are in precisely one of the training, testing or validation sets. Ensuring observations from each drifter are not split between sets will ensure that the training data does not contain any information about the testing or validation sets via correlation.\n",
    "\n",
    "O'Malley et al. (2023) deal with this issue using cluster sampling. That is, spliting the data into clusters defined by their corresponding drifter ID, then randomly sampling the clusters into the training, testing, and validation sets containing 81%, 10% and 9% of the drifter IDs respectively. However, there is significant variation between the number of observations found in each of the drifter ID clusters meaning that the proportion of the overall data found in each of the sets may be significantly different than the nominal 81-10-9 split. At its most extreme, this discrepancy could result in testing and training sets that are of comporable sizes. \n",
    "\n",
    "In this notebook, we will investigate whether the sizes of the training, testing, and validation sets that result from 81-10-9 cluster sampling differ signficantly from the nominal 81-10-9 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t,ttest_1samp\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('seaducks'), '..')))\n",
    "from seaducks.model_selection import train_test_validation_split\n",
    "from seaducks.config import config\n",
    "\n",
    "path_to_data = '../data/filtered_nao_drifters_with_sst_gradient.h5'\n",
    "data = pd.read_hdf(path_to_data)\n",
    "# add day of the year as an index (to be added to the data later)\n",
    "data['day_of_year'] = data['time'].apply(lambda t : t.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "To identify if the actual sizes of the training, testing, and validation sets differ significantly from the nominal 81-10-9 values, we will cluster sample the data by drifter ID `N=100000` times and calculate the resulting proportions of the overall data made up by each of the three sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(data.index)                                     # number of drifter observations\n",
    "N = 100000                                                              # number of repeats for hypothesis tests\n",
    "\n",
    "count_by_id = data.groupby('id').size()                                 # grouping observations by id\n",
    "ids, size_by_id = np.array(count_by_id.index), np.array(count_by_id)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test the impact of cluster sampling using the implementation carried out by O'Malley et al. (2023) and the implementation used in this package. By cycling through random seeds, we have also obtained a seed that results in training, testing, and validation set proportions that are close to the nominal values which we also include and is the default `random_state` in this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % ------------------------------------ O'Malley et al. (2023) implementation ------------------------------------------ %\n",
    "\n",
    "'''MV_Prediction/experiments/dispatcher.py lines 31-39'''\n",
    "def random_id_subset(ids, pc=0.1):\n",
    "    unique_id = np.unique(ids)\n",
    "    N_unique = len(unique_id)\n",
    "    np.random.shuffle(unique_id)\n",
    "    in_test = int(N_unique * pc)\n",
    "    test_ids = unique_id[:in_test]\n",
    "    test_mask = np.in1d(ids, test_ids)\n",
    "    train_mask = np.invert(test_mask)\n",
    "    return train_mask, test_mask\n",
    "\n",
    "''' from MV_Prediction/experiments/dispatcher.py'''\n",
    "N_runs = N                                             # L97 (adaptated)\n",
    "shuffle_seed = 500                                              # L80\n",
    "np.random.seed(shuffle_seed)                                    # L98\n",
    "splits = [random_id_subset(ids) for _ in range(N_runs)]         # L99 (adapted)\n",
    "total_data_size = count_by_id.sum()\n",
    "\n",
    "OM_train_test_val_proportions = []\n",
    "\n",
    "for (train_mask, test_mask) in splits:                                # L101 (adapted)\n",
    "    test_ids = ids[test_mask]                                         # L103 (adapted)\n",
    "    train_ids = ids[train_mask] # auxillary set                       # L106 (adapted)\n",
    "\n",
    "    train_mask, valid_mask = random_id_subset(train_ids, pc=0.1)      # L48 (adapted)\n",
    "    new_train_ids = train_ids[train_mask]\n",
    "    valid_ids = train_ids[valid_mask]\n",
    "    \n",
    "    # get the proportion of each set\n",
    "    train_size = (count_by_id[new_train_ids]).sum()\n",
    "    test_size = (count_by_id[test_ids]).sum()\n",
    "    validation_size = (count_by_id[valid_ids]).sum()\n",
    "\n",
    "    OM_train_test_val_proportions.append([(count_by_id[new_train_ids]).sum(), (count_by_id[test_ids]).sum(),(count_by_id[valid_ids]).sum()])\n",
    "\n",
    "\n",
    "OM_train_test_val_proportions = np.array(OM_train_test_val_proportions)/total_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % ----------------------------- SeaDucks implementation ----------------------------------- %\n",
    "\n",
    "train_test_val_proportions = []\n",
    "\n",
    "for ii in range(N):\n",
    "    _,_,_,Y_train,Y_test,Y_val = train_test_validation_split(ids, size_by_id,\n",
    "                                                             test_frac = 0.10, validation_frac = 0.09)\n",
    "    train_test_val_proportions.append([sum(Y_train),sum(Y_test),sum(Y_val)])\n",
    "\n",
    "train_test_val_proportions = np.array(train_test_val_proportions)/number_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % ----------------------------- SeaDucks implementation with preselected seed ----------------------------------- %\n",
    "\n",
    "\n",
    "_,_,_,Y_train,Y_test,Y_val = train_test_validation_split(ids, size_by_id,\n",
    "                                                             test_frac = 0.10, validation_frac = 0.09,random_state=np.random.seed(63012))\n",
    "train_test_val_proportions_seeded = ([sum(Y_train),sum(Y_test),sum(Y_val)])\n",
    "\n",
    "train_test_val_proportions_seeded = np.array(train_test_val_proportions_seeded)/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two One-Sided Student's $t$-Tests (TOST)\n",
    "\n",
    "Since we are working within an application, if the training, testing, validation split differs very slightly from 81-10-9, the impact of this will be negligible in practice so we will allow for the mean proportion to differ from 0.81 up to $\\delta = 5\\times 10^{-5}$. This tolerance will result in each of the three sets differing from nominal values by no more than 20 observation.\n",
    "\n",
    "Since the sample means of the training, testing, validation data proportion approximately follow normal distributions, respectively (CLT) and each combination of training, testing, and validation sets is independent, we can use the two-sided Student's $t$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest permitted difference from nominal values: 20 observations\n"
     ]
    }
   ],
   "source": [
    "delta = 0.00005\n",
    "\n",
    "print(f\"Largest permitted difference from nominal values: {int(np.floor(delta*number_of_samples))} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TOST(train_test_val_proportions,train_test_val_flag,delta,popmean):\n",
    "    set_proportions = train_test_val_proportions[:,train_test_val_flag]\n",
    "\n",
    "    print(f\"sample mean:{np.mean(set_proportions)}\")\n",
    "    _, p1 = ttest_1samp(set_proportions-popmean, -delta,\n",
    "                        axis=None, nan_policy='propagate', alternative='greater')\n",
    "    \n",
    "    _, p2 = ttest_1samp(set_proportions-popmean, delta,\n",
    "                        axis=None, nan_policy='propagate', alternative='less')\n",
    "\n",
    "    set_type = ['training', 'testing', 'validation']\n",
    "    alpha = 0.05\n",
    "    print(\"\\n ------------- Test 1 -------------\")\n",
    "    if p1 < alpha:\n",
    "        print(f\"\\nReject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu_hat, is significantly small compared to the nominal value, mu:\")\n",
    "        print(f\"mu_hat - {popmean} <= -{delta}\")\n",
    "    else:\n",
    "        print(f\"\\nFail to reject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu_hat, is not signficantly small compared to the nominal value, mu:\")\n",
    "        print(f\"mu_hat  - {popmean} > -{delta}\")\n",
    "    print(f\"\\n p-value for Test 1: {p1:.3f}\")\n",
    "\n",
    "    print(\"\\n ------------- Test 2 -------------\")\n",
    "    if p2 < alpha:\n",
    "        print(f\"\\nReject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu_hat, is significantly large compared to the nominal value, mu:\")\n",
    "        print(f\"mu_hat - {popmean} >= {delta}\")\n",
    "    else:\n",
    "        print(f\"\\nFail to reject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu_hat, is not significantly large compared to the nominal value, mu:\")\n",
    "        print(f\"mu_hat - {popmean} < {delta}\")\n",
    "        \n",
    "    print(f\"\\n p-value for Test 2: {p2:.3f}\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of TOST is comprised of two tests with the following forms:\n",
    "\n",
    "**Test 1: The mean proportion is smaller than the nominal value**\n",
    "\n",
    "$H_0^{(1)}$: The mean proportion of the data assigned to `{set type}` set>, $\\hat{\\mu} - \\mu \\leq -\\delta$. \n",
    "\n",
    "$H_1^{(1)}$: The mean proportion of the data assigned to `{set type}` set>, $\\hat{\\mu} - \\mu > -\\delta$. \n",
    "\n",
    "**Test 2: The mean proportion is larger than the nominal value**\n",
    "\n",
    "$H_0^{(2)}$: The mean proportion of the data assigned to `{set type}` set>, $\\hat{\\mu} - \\mu \\geq \\delta$.\n",
    "\n",
    "$H_1^{(2)}$: The mean proportion of the data assigned to `{set type}` set>, $\\hat{\\mu} - \\mu < \\delta$.\n",
    "\n",
    "Significance Level: 5%\n",
    "\n",
    "where $\\hat{\\mu}$ is the sample mean, $\\mu$ is the nominal proportion, $\\delta=5\\times10^{-5}$ is the tolerance, and the set types are training, testing, and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Data Proportion vs Nominal Value TOST [for the O'Malley et al. (2023) implementation]\n",
      "sample mean:0.8105521506621232\n",
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to training, mu_hat, is significantly small compared to the nominal value, mu:\n",
      "mu_hat - 0.81 <= -5e-05\n",
      "\n",
      " p-value for Test 1: 0.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to training, mu_hat, is not significantly large compared to the nominal value, mu:\n",
      "mu_hat - 0.81 < 5e-05\n",
      "\n",
      " p-value for Test 2: 1.000\n",
      "\n",
      "=========================================================================================================================================\n",
      "\n",
      " Training Data Proportion vs Nominal Value TOST [for the SeaDucks implementation]\n",
      "sample mean:0.8097174964563796\n",
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to training, mu_hat, is not signficantly small compared to the nominal value, mu:\n",
      "mu_hat  - 0.81 > -5e-05\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to training, mu_hat, is significantly large compared to the nominal value, mu:\n",
      "mu_hat - 0.81 >= 5e-05\n",
      "\n",
      " p-value for Test 2: 0.000\n",
      "\n",
      "=========================================================================================================================================\n",
      "\n",
      " Training Data Proportion vs Nominal Value [for the SeaDucks seeded implementation]\n",
      "\n",
      "Training data proportion: 0.8100376691714724\n",
      "Training proportion - nominal value: 3.766917147229876e-05\n"
     ]
    }
   ],
   "source": [
    "# TOST for training data\n",
    "popmean = 0.81\n",
    "train_test_val_flag = 0 # training set\n",
    "print(\"\\n Training Data Proportion vs Nominal Value TOST [for the O'Malley et al. (2023) implementation]\")\n",
    "\n",
    "TOST(OM_train_test_val_proportions,train_test_val_flag,delta,popmean)\n",
    "\n",
    "print(\"\\n=========================================================================================================================================\")\n",
    "\n",
    "print(\"\\n Training Data Proportion vs Nominal Value TOST [for the SeaDucks implementation]\")\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)\n",
    "\n",
    "print(\"\\n=========================================================================================================================================\")\n",
    "\n",
    "print(\"\\n Training Data Proportion vs Nominal Value [for the SeaDucks seeded implementation]\")\n",
    "print(f\"\\nTraining data proportion: {train_test_val_proportions_seeded[train_test_val_flag]}\")\n",
    "print(f\"Training proportion - nominal value: {train_test_val_proportions_seeded[train_test_val_flag]-popmean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Data Proportion vs Nominal Value TOST [for the O'Malley et al. (2023) implementation]\n",
      "sample mean:0.09978165426399488\n",
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to testing, mu_hat, is not signficantly small compared to the nominal value, mu:\n",
      "mu_hat  - 0.1 > -5e-05\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to testing, mu_hat, is significantly large compared to the nominal value, mu:\n",
      "mu_hat - 0.1 >= 5e-05\n",
      "\n",
      " p-value for Test 2: 0.000\n",
      "\n",
      "=========================================================================================================================================\n",
      "\n",
      " Testing Data Proportion vs Nominal Value TOST [for the SeaDucks implementation]\n",
      "sample mean:0.10019171016096776\n",
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to testing, mu_hat, is significantly small compared to the nominal value, mu:\n",
      "mu_hat - 0.1 <= -5e-05\n",
      "\n",
      " p-value for Test 1: 0.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to testing, mu_hat, is not significantly large compared to the nominal value, mu:\n",
      "mu_hat - 0.1 < 5e-05\n",
      "\n",
      " p-value for Test 2: 1.000\n",
      "\n",
      "=========================================================================================================================================\n",
      "\n",
      " Testing Data Proportion vs Nominal Value [for the SeaDucks seeded implementation]\n",
      "\n",
      "Testing data proportion: 0.09999077687811887\n",
      "Testing proportion - nominal value: -9.223121881132834e-06\n"
     ]
    }
   ],
   "source": [
    "# TOST for testing data\n",
    "popmean = 0.10\n",
    "train_test_val_flag = 1 # testing set\n",
    "print(\"\\n Testing Data Proportion vs Nominal Value TOST [for the O'Malley et al. (2023) implementation]\")\n",
    "\n",
    "TOST(OM_train_test_val_proportions,train_test_val_flag,delta,popmean)\n",
    "\n",
    "print(\"\\n=========================================================================================================================================\")\n",
    "\n",
    "print(\"\\n Testing Data Proportion vs Nominal Value TOST [for the SeaDucks implementation]\")\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)\n",
    "\n",
    "print(\"\\n=========================================================================================================================================\")\n",
    "\n",
    "print(\"\\n Testing Data Proportion vs Nominal Value [for the SeaDucks seeded implementation]\")\n",
    "print(f\"\\nTesting data proportion: {train_test_val_proportions_seeded[train_test_val_flag]}\")\n",
    "print(f\"Testing proportion - nominal value: {train_test_val_proportions_seeded[train_test_val_flag]-popmean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Data Proportion vs Nominal Value TOST [for the O'Malley et al. (2023) implementation]\n",
      "sample mean:0.08966619507388206\n",
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to validation, mu_hat, is not signficantly small compared to the nominal value, mu:\n",
      "mu_hat  - 0.09 > -5e-05\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to validation, mu_hat, is significantly large compared to the nominal value, mu:\n",
      "mu_hat - 0.09 >= 5e-05\n",
      "\n",
      " p-value for Test 2: 0.000\n",
      "\n",
      "=========================================================================================================================================\n",
      "\n",
      " Validation Data Proportion vs Nominal Value TOST [for the SeaDucks implementation]\n",
      "sample mean:0.09009079338265277\n",
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to validation, mu_hat, is significantly small compared to the nominal value, mu:\n",
      "mu_hat - 0.09 <= -5e-05\n",
      "\n",
      " p-value for Test 1: 0.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to validation, mu_hat, is not significantly large compared to the nominal value, mu:\n",
      "mu_hat - 0.09 < 5e-05\n",
      "\n",
      " p-value for Test 2: 0.993\n",
      "\n",
      "=========================================================================================================================================\n",
      "\n",
      " Validation Data Proportion vs Nominal Value [for the SeaDucks seeded implementation]\n",
      "\n",
      "Validation data proportion: 0.08997155395040873\n",
      "Validation proportion - nominal value: -2.8446049591263067e-05\n"
     ]
    }
   ],
   "source": [
    "# TOST for validation data\n",
    "popmean = 0.09\n",
    "train_test_val_flag = 2 # validation set\n",
    "print(\"\\n Validation Data Proportion vs Nominal Value TOST [for the O'Malley et al. (2023) implementation]\")\n",
    "\n",
    "TOST(OM_train_test_val_proportions,train_test_val_flag,delta,popmean)\n",
    "\n",
    "print(\"\\n=========================================================================================================================================\")\n",
    "\n",
    "print(\"\\n Validation Data Proportion vs Nominal Value TOST [for the SeaDucks implementation]\")\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)\n",
    "\n",
    "print(\"\\n=========================================================================================================================================\")\n",
    "\n",
    "print(\"\\n Validation Data Proportion vs Nominal Value [for the SeaDucks seeded implementation]\")\n",
    "print(f\"\\nValidation data proportion: {train_test_val_proportions_seeded[train_test_val_flag]}\")\n",
    "print(f\"Validation proportion - nominal value: {train_test_val_proportions_seeded[train_test_val_flag]-popmean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = config['random_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_interval(data, future_sample_size=1, alpha=0.05):\n",
    "    n = len(data) \n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1) \n",
    "    \n",
    "    t_crit = t.ppf(1 - alpha / 2, df=n - 1)\n",
    "    se_prediction = np.sqrt(std**2 + (std**2 / future_sample_size)) \n",
    "    \n",
    "    # Prediction interval\n",
    "    margin_of_error = t_crit * se_prediction\n",
    "    lower = round((mean - margin_of_error)*100,3)\n",
    "    upper = round((mean + margin_of_error)*100,3)\n",
    "    \n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction interval (train proportions): (79.042, 83.069)\n",
      "\n",
      "Prediction interval (test proportions): (8.439, 11.517)\n",
      "\n",
      "Prediction interval (validation proportions): (7.5, 10.434)\n"
     ]
    }
   ],
   "source": [
    "set_type = ['train', 'test', 'validation']\n",
    "\n",
    "for ii,name in enumerate(set_type):\n",
    "    print(f\"\\nPrediction interval ({name} proportions): {prediction_interval(OM_train_test_val_proportions[:,ii], future_sample_size=1, alpha=0.05)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction interval (train proportions): (78.961, 82.979)\n",
      "\n",
      "Prediction interval (test proportions): (8.48, 11.56)\n",
      "\n",
      "Prediction interval (validation proportions): (7.537, 10.482)\n"
     ]
    }
   ],
   "source": [
    "set_type = ['train', 'test', 'validation']\n",
    "\n",
    "for ii,name in enumerate(set_type):\n",
    "    print(f\"\\nPrediction interval ({name} proportions): {prediction_interval(train_test_val_proportions[:,ii], future_sample_size=1, alpha=0.05)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "1. Whether the proportion of the overall data contained within the training, testing, and validation sets are practically equal to the nominal nominal 81-10-9 proportions.\n",
    "\n",
    "The TOST analysis above shows that cluster sampling the drifter data by ID according to a training, testing, validation data split of 81-10-9, on average, leads to a training, testing, and validation datasets that form within \n",
    "\n",
    "* $(80.05 \\leq \\_ < 81.05)\\%$, \n",
    "* $(9.05 \\leq \\_ < 10.05)\\%$, \n",
    "* $(8.05 < \\_ < 9.05)\\%$ \n",
    "\n",
    "of the total drifter dataset, respectively at the 5% significance level.\n",
    "\n",
    "2. The nominal proportion of the overall dataset for all three data set types are found in their respective 95% prediction intervals. However, individual variability between the number of observations in each drifter ID cluster results in wide prediction intervals, thus for each train-test-validation split, there may be notable variability from the nominal values.\n",
    "\n",
    "The 95% prediction intervals (the intervals in which the proportion of the overall data each set will contain 95% of the time) are:\n",
    "\n",
    "|Data subset| Nominal Proportion| 95% Prediction Interval|\n",
    "|---|---|---|\n",
    "|Training |81\\%| $(79.0, 83.0)\\%$|\n",
    "|Testing| $10\\%$ | $(8.5, 11.6)\\%$|\n",
    "|Validation| $9\\%$| $(7.5, 10.5)\\%$|\n",
    "\n",
    "There is not very much uncertainty in the mean (TOST). Individual variability is where the potential problem lies (Prediction Intervals).\n",
    "\n",
    "It's up to my discretion as to whether this is a problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
