{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Impact of Cluster Sampling on the Size of the Training, Testing, and Validation Sets\n",
    "\n",
    "When training the MVN NGBoost model on the drifter data, we must take extra care to ensure that information about the testing and validation sets are not inadvertedly introduced into the training data. The ~400,000 drifter observations that form our data set come from ~2000 unique drifters. We expect that observations taken by the same drifter are likely to be highly correlated so we ensure that all of the observations made by any single drifter are in precisely one of the training, testing or validation sets. Ensuring observations from each drifter are not split between sets will ensure that the training data does not contain any extra information via correlation.\n",
    "\n",
    "O'Malley et al. (2023) deal with this issue using cluster sampling. That is, spliting the data into clusters defined by their corresponding drifter ID, then randomly sampling the clusters into the training, testing, and validation sets containing 81%, 10% and 9% of the drifter IDs respectively. However, there is significant variation between the number of observations found in each of the drifter ID clusters meaning that the propertion of the overall data found in each of the sets may be significantly different than the nominal 81-10-9 split. At its most extreme, this discrepancy could result in testing and training sets that are of comporable sizes. \n",
    "\n",
    "In this notebook, we will investigate whether the sizes of the training, testing, and validation sets that result from 81-10-9 cluster sampling differ signficantly from the nominal 81-10-9 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path_to_data = '../data/filtered_nao_drifters_with_sst_gradient.h5'\n",
    "data = pd.read_hdf(path_to_data)\n",
    "# add day of the year as an index (to be added to the data later)\n",
    "data['day_of_year'] = data['time'].apply(lambda t : t.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the drifter IDs into training, testing and validation \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_validation_split(X, Y,*,\n",
    "                                test_frac = 0.10, validation_frac = 0.09, \n",
    "                                random_state = None, shuffle = True, stratify = None):\n",
    "    \n",
    "    X_aux, X_test, Y_aux, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=test_frac, random_state = random_state, shuffle = shuffle, stratify = stratify)\n",
    "    if validation_frac == 0:\n",
    "        return X_aux, X_test, Y_aux, Y_test\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_aux, Y_aux,\n",
    "                                                        test_size=validation_frac/(1 - test_frac), random_state = random_state, shuffle = shuffle, stratify = stratify)\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split drifter IDs into 81-10-9 and calculate the proportion of data in each of the sets\n",
    "\n",
    "number_of_samples = len(data.index)\n",
    "N = 100000 # number of repeats for hypothesis tests\n",
    "\n",
    "count_by_id = data.groupby('id').size()\n",
    "X, Y = np.array(count_by_id.index), np.array(count_by_id)\n",
    "train_test_val_proportions = []\n",
    "\n",
    "for ii in range(N):\n",
    "    _,_,_,Y_train,Y_test,Y_val = train_test_validation_split(X, Y,\n",
    "                                                             test_frac = 0.10, validation_frac = 0.09)\n",
    "    train_test_val_proportions.append([sum(Y_train),sum(Y_test),sum(Y_val)])\n",
    "\n",
    "train_test_val_proportions = np.array(train_test_val_proportions)/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "With the proportions of data in training, testing, and cross validations set calculated above for `N=100000` repetitions, we will test the following hypotheses:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two One-Sided Student's $t$-Tests (TOST)\n",
    "\n",
    "Since we are working within an application, if the training, testing, validation split differs very slightly from 81-10-9, the impact of this will be negligible in practice so we will allow for the mean proportion to differ from 0.81 up to $\\delta = 0.0005$. Since the sample means of the training, testing, validation data proportion approximately follow normal distributions, respectively (CLT) and each combination of training, testing, and validation sets is independent, we can use the two-sided Student's $t$-test.\n",
    "\n",
    "Test 1\n",
    "\n",
    "$H_0^{(1)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 \\leq \\delta$.\n",
    "\n",
    "$H_1^{(1)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 > \\delta$.\n",
    "\n",
    "Test 2\n",
    "\n",
    "$H_0^{(2)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 \\geq \\delta$.\n",
    "\n",
    "$H_1^{(2)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 < \\delta$.\n",
    "\n",
    "Significance Level: 5%\n",
    "\n",
    "and similarly for the proportion of the data assigned to the testing and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "def TOST(train_test_val_proportions,train_test_val_flag,delta,popmean):\n",
    "    train_proportions = train_test_val_proportions[:,train_test_val_flag]\n",
    "    _, p1 = ttest_1samp(train_proportions-popmean, -delta,\n",
    "                        axis=None, nan_policy='propagate', alternative='less')\n",
    "\n",
    "    _, p2 = ttest_1samp(train_proportions-popmean, delta,\n",
    "                        axis=None, nan_policy='propagate', alternative='greater')\n",
    "\n",
    "    set_type = ['training', 'testing', 'validation']\n",
    "    alpha = 0.05\n",
    "    print(\"\\n ------------- Test 1 -------------\")\n",
    "    if p1 < alpha:\n",
    "        print(f\"\\nReject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} <= -{delta}\")\n",
    "    else:\n",
    "        print(f\"\\nFail to reject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} > -{delta}\")\n",
    "    print(f\"\\n p-value for Test 1: {p1:.3f}\")\n",
    "\n",
    "    print(\"\\n ------------- Test 2 -------------\")\n",
    "    if p1 < alpha:\n",
    "        print(f\"\\nReject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} >= {delta}\")\n",
    "    else:\n",
    "        print(f\"\\nFail to reject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} < {delta}\")\n",
    "    print(f\"\\n p-value for Test 2: {p2:.3f}\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to training, mu - 0.81 > -0.0005\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to training, mu - 0.81 < 0.0005\n",
      "\n",
      " p-value for Test 2: 1.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for training data\n",
    "\n",
    "popmean = 0.81\n",
    "train_test_val_flag = 0 # training set\n",
    "\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to testing, mu - 0.1 > -0.0005\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to testing, mu - 0.1 < 0.0005\n",
      "\n",
      " p-value for Test 2: 1.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for testing data\n",
    "\n",
    "popmean = 0.10\n",
    "train_test_val_flag = 1 # testing set\n",
    "\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to validation, mu - 0.09 > -0.0005\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to validation, mu - 0.09 < 0.0005\n",
      "\n",
      " p-value for Test 2: 1.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for validation data\n",
    "\n",
    "popmean = 0.09\n",
    "train_test_val_flag = 2 # validation set\n",
    "\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction intervals (re do this later)\n",
    "from scipy.stats import t\n",
    "\n",
    "def prediction_interval(data, future_sample_size=1, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Compute the prediction interval for a future observation or sample mean.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, sample data.\n",
    "    - future_sample_size: int, size of the future sample (default: 1 for individual observation).\n",
    "    - confidence: float, confidence level (default: 0.95).\n",
    "    \n",
    "    Returns:\n",
    "    - interval: tuple, (lower bound, upper bound) of the prediction interval.\n",
    "    \"\"\"\n",
    "    n = len(data)  # current sample size\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)  # sample standard deviation\n",
    "    alpha = 1 - confidence\n",
    "    \n",
    "    # Critical t-value\n",
    "    t_crit = t.ppf(1 - alpha / 2, df=n - 1)\n",
    "    \n",
    "    # Standard error terms\n",
    "    se_mean = std / np.sqrt(n)  # standard error of the mean\n",
    "    se_prediction = np.sqrt(std**2 + (std**2 / future_sample_size))  # for individual or sample mean\n",
    "    \n",
    "    # Prediction interval\n",
    "    margin_of_error = t_crit * se_prediction\n",
    "    lower = round((mean - margin_of_error)*100,3)\n",
    "    upper = round((mean + margin_of_error)*100,3)\n",
    "    \n",
    "    return lower, upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction interval (train proportions): (78.955, 82.978)\n",
      "\n",
      "Prediction interval (test proportions): (8.483, 11.562)\n",
      "\n",
      "Prediction interval (validation proportions): (7.54, 10.482)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPrediction interval (train proportions): {prediction_interval(train_test_val_proportions[:,0], future_sample_size=1, confidence=0.95)}\")\n",
    "print(f\"\\nPrediction interval (test proportions): {prediction_interval(train_test_val_proportions[:,1], future_sample_size=1, confidence=0.95)}\")\n",
    "print(f\"\\nPrediction interval (validation proportions): {prediction_interval(train_test_val_proportions[:,2], future_sample_size=1, confidence=0.95)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "To do: Properly discuss\n",
    "1. Whether the mean sizes are practically equal.\n",
    "2. An interval in which the size of each set will sit 95% of the time\n",
    "\n",
    "\n",
    "Cluster sampling the drifter data by ID according to a training, testing, validation data split of 81-10-9, on average, leads to a training, testing, and validation datasets that form within $(80.5 \\leq \\_ < 81.5)\\%$, $(9.5 \\leq \\_ < 10.5)\\%$, $(8.5 < \\_ < 9.5)\\%$ of the total drifter dataset, respectively at the 5% significance level.\n",
    "\n",
    "The 95% prediction intervals (An interval in which the size of each set will sit 95% of the time) are:\n",
    "\n",
    "\n",
    "|Data subset| Nominal Proportion| 95% Prediction Interval|\n",
    "|---|---|---|\n",
    "|Training |81\\%| $(79.0, 83.0)\\%$|\n",
    "|Testing| $10\\%$ | $(8.5, 11.6)\\%$|\n",
    "|Validation| $9\\%$| $(7.5, 10.5)\\%$|\n",
    "\n",
    "There is not very much uncertainty in the mean (TOST). Individual variability is where the potential problem lies (Prediction Intervals).\n",
    "\n",
    "It's up to my discretion as to whether this is a problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
