{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Impact of Cluster Sampling on the Size of the Training, Testing, and Validation Sets\n",
    "\n",
    "When training the MVN NGBoost model on the drifter data, we must take extra care to ensure that information about the testing and validation sets are not inadvertedly introduced into the training data. The ~400,000 drifter observations that form our data set come from ~2000 unique drifters. We expect that observations taken by the same drifter are likely to be highly correlated so we ensure that all of the observations made by any single drifter are in precisely one of the training, testing or validation sets. Ensuring observations from each drifter are not split between sets will ensure that the training data does not contain any extra information via correlation.\n",
    "\n",
    "O'Malley et al. (2023) deal with this issue using cluster sampling. That is, spliting the data into clusters defined by their corresponding drifter ID, then randomly sampling the clusters into the training, testing, and validation sets containing 81%, 10% and 9% of the drifter IDs respectively. However, there is significant variation between the number of observations found in each of the drifter ID clusters meaning that the propertion of the overall data found in each of the sets may be significantly different than the nominal 81-10-9 split. At its most extreme, this discrepancy could result in testing and training sets that are of comporable sizes. \n",
    "\n",
    "In this notebook, we will investigate whether the sizes of the training, testing, and validation sets that result from 81-10-9 cluster sampling differ signficantly from the nominal 81-10-9 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path_to_data = '../data/filtered_nao_drifters_with_sst_gradient.h5'\n",
    "data = pd.read_hdf(path_to_data)\n",
    "# add day of the year as an index (to be added to the data later)\n",
    "data['day_of_year'] = data['time'].apply(lambda t : t.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the drifter IDs into training, testing and validation \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_validation_split(X, Y,*,\n",
    "                                test_frac = 0.10, validation_frac = 0.09, \n",
    "                                random_state = None, shuffle = True, stratify = None):\n",
    "    \n",
    "    X_aux, X_test, Y_aux, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=test_frac, random_state = random_state, shuffle = shuffle, stratify = stratify)\n",
    "    if validation_frac == 0:\n",
    "        return X_aux, X_test, Y_aux, Y_test\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_aux, Y_aux,\n",
    "                                                        test_size=validation_frac/(1 - test_frac), random_state = random_state, shuffle = shuffle, stratify = stratify)\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split drifter IDs into 81-10-9 and calculate the proportion of data in each of the sets\n",
    "\n",
    "number_of_samples = len(data.index)\n",
    "N = 1000 # number of repeats for hypothesis tests\n",
    "\n",
    "count_by_id = data.groupby('id').size()\n",
    "X, Y = np.array(count_by_id.index), np.array(count_by_id)\n",
    "train_test_val_proportions = []\n",
    "\n",
    "for ii in range(N):\n",
    "    _,_,_,Y_train,Y_test,Y_val = train_test_validation_split(X, Y,\n",
    "                                                             test_frac = 0.10, validation_frac = 0.09)\n",
    "    train_test_val_proportions.append([sum(Y_train),sum(Y_test),sum(Y_val)])\n",
    "\n",
    "train_test_val_proportions = np.array(train_test_val_proportions)/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "With the proportions of data in training, testing, and cross validations set calculated above for `N=10000` repetitions, we will test the following hypotheses:\n",
    "\n",
    "### $\\chi^2$ test for normality\n",
    "\n",
    "To make sure that we can use the (two-sided) student's $t$-test for the mean training data proportion and the ratio between the sizes of the validation and testing sets, we first test for normality.\n",
    "\n",
    "$H_0:$ The proportion of the dataset that is assigned to training follows a normal distribution.\n",
    "\n",
    "$H_1:$ The proportion of the dataset that is assigned to training does not follow a normal distribution.\n",
    "\n",
    "Significance Level: 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fail to reject H0: The proportion of the data that is assigned to training follows a normal distribution.\n",
      "\n",
      " p value: 0.544\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "train_proportions = train_test_val_proportions[:,0]\n",
    "\n",
    "_, p = normaltest(train_proportions, nan_policy='propagate')\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"\\nReject H0: The proportion of the data that is assigned to training does not follow a normal distribution.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject H0: The proportion of the data that is assigned to training follows a normal distribution.\")\n",
    "\n",
    "print(f\"\\n p value: {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: The ratio between the sizes of the validation and testing sets follows a normal distribution\n",
    "\n",
    "$H_1$: The ratio between the sizes of the validation and testing sets do not follow a normal distribution\n",
    "\n",
    "Significance Level: 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reject H0: The ratio between the sizes of the validation and testing sets does not follow a normal distribution\n",
      "\n",
      " p value: 0.011\n"
     ]
    }
   ],
   "source": [
    "validation_test_ratio = train_test_val_proportions[:,2]/train_test_val_proportions[:,1]\n",
    "\n",
    "_, p = normaltest(validation_test_ratio, nan_policy='propagate')\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"\\nReject H0: The ratio between the sizes of the validation and testing sets does not follow a normal distribution\")\n",
    "else:\n",
    "    print(\"\\nFail to reject H0: The ratio between the sizes of the validation and testing sets follows a normal distribution\")\n",
    "\n",
    "print(f\"\\n p value: {p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Sided Student's $t$-Tests\n",
    "\n",
    "Since the training data proportion and the ratio between the sizes of the validation and testing sets follow normal distributions and each combination of training, testing, and validation sets is independent, we can use the two-sided Student's $t$-test.\n",
    "\n",
    "$H_0$: The mean proportion of the data assigned to training, $\\mu \\neq 0.81$\n",
    "\n",
    "$H_1$: The mean proportion of the data assigned to training, $\\mu = 0.81$\n",
    "\n",
    "Significance Level: 5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reject H0: The mean proportion of the data assigned to training, mu != 0.81\n",
      "\n",
      " p value: 0.029\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "popmean = 0.81\n",
    "\n",
    "_, p = ttest_1samp(train_proportions, popmean,\n",
    "                      axis=None, nan_policy='propagate', alternative='two-sided')\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"\\nReject H0: The mean proportion of the data assigned to training, mu != 0.81\")\n",
    "else:\n",
    "    print(\"\\nFail to reject H0: The mean proportion of the data assigned to training, mu = 0.81\")\n",
    "\n",
    "print(f\"\\n p value: {p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: The mean ratio between the sizes of the validation and testing sets, $\\mu \\neq 0.9$\n",
    "\n",
    "$H_1$: The mean ratio between the sizes of the validation and testing sets, $\\mu = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fail to reject H0: The mean ratio between the sizes of the validation and testing sets, mu = 0.9\n",
      "\n",
      " p value: 0.718\n"
     ]
    }
   ],
   "source": [
    "popmean = 0.9\n",
    "\n",
    "_, p = ttest_1samp(validation_test_ratio, popmean,\n",
    "                      axis=None, nan_policy='propagate', alternative='two-sided')\n",
    "\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"\\nReject H0: The mean ratio between the sizes of the validation and testing sets, mu != 0.9\")\n",
    "else:\n",
    "    print(\"\\nFail to reject H0: The mean ratio between the sizes of the validation and testing sets, mu = 0.9\")\n",
    "\n",
    "print(f\"\\n p value: {p:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
