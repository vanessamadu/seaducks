{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Impact of Cluster Sampling on the Size of the Training, Testing, and Validation Sets\n",
    "\n",
    "When training the MVN NGBoost model on the drifter data, we must take extra care to ensure that information about the testing and validation sets are not inadvertedly introduced into the training data. The ~400,000 drifter observations that form our data set come from ~2000 unique drifters. We expect that observations taken by the same drifter are likely to be highly correlated so we ensure that all of the observations made by any single drifter are in precisely one of the training, testing or validation sets. Ensuring observations from each drifter are not split between sets will ensure that the training data does not contain any extra information via correlation.\n",
    "\n",
    "O'Malley et al. (2023) deal with this issue using cluster sampling. That is, spliting the data into clusters defined by their corresponding drifter ID, then randomly sampling the clusters into the training, testing, and validation sets containing 81%, 10% and 9% of the drifter IDs respectively. However, there is significant variation between the number of observations found in each of the drifter ID clusters meaning that the propertion of the overall data found in each of the sets may be significantly different than the nominal 81-10-9 split. At its most extreme, this discrepancy could result in testing and training sets that are of comporable sizes. \n",
    "\n",
    "In this notebook, we will investigate whether the sizes of the training, testing, and validation sets that result from 81-10-9 cluster sampling differ signficantly from the nominal 81-10-9 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path_to_data = '../data/filtered_nao_drifters_with_sst_gradient.h5'\n",
    "data = pd.read_hdf(path_to_data)\n",
    "# add day of the year as an index (to be added to the data later)\n",
    "data['day_of_year'] = data['time'].apply(lambda t : t.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "def TOST(train_test_val_proportions,train_test_val_flag,delta,popmean):\n",
    "    train_proportions = train_test_val_proportions[:,train_test_val_flag]\n",
    "    _, p1 = ttest_1samp(train_proportions-popmean, -delta,\n",
    "                        axis=None, nan_policy='propagate', alternative='less')\n",
    "\n",
    "    _, p2 = ttest_1samp(train_proportions-popmean, delta,\n",
    "                        axis=None, nan_policy='propagate', alternative='greater')\n",
    "\n",
    "    set_type = ['training', 'testing', 'validation']\n",
    "    alpha = 0.05\n",
    "    print(\"\\n ------------- Test 1 -------------\")\n",
    "    if p1 < alpha:\n",
    "        print(f\"\\nReject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} <= -{delta}\")\n",
    "    else:\n",
    "        print(f\"\\nFail to reject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} > -{delta}\")\n",
    "    print(f\"\\n p-value for Test 1: {p1:.3f}\")\n",
    "\n",
    "    print(\"\\n ------------- Test 2 -------------\")\n",
    "    if p2 < alpha:\n",
    "        print(f\"\\nReject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} >= {delta}\")\n",
    "    else:\n",
    "        print(f\"\\nFail to reject H0: The mean proportion of the data assigned to {set_type[train_test_val_flag]}, mu - {popmean} < {delta}\")\n",
    "    print(f\"\\n p-value for Test 2: {p2:.3f}\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction intervals (re do this later)\n",
    "from scipy.stats import t\n",
    "\n",
    "def prediction_interval(data, future_sample_size=1, alpha=0.05):\n",
    "    n = len(data) \n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1) \n",
    "    \n",
    "    t_crit = t.ppf(1 - alpha / 2, df=n - 1)\n",
    "\n",
    "    se_prediction = np.sqrt(std**2 + (std**2 / future_sample_size))  # for individual or sample mean\n",
    "    \n",
    "    # Prediction interval\n",
    "    margin_of_error = t_crit * se_prediction\n",
    "    lower = round((mean - margin_of_error)*100,3)\n",
    "    upper = round((mean + margin_of_error)*100,3)\n",
    "    \n",
    "    return lower, upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the drifter IDs into training, testing and validation \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_validation_split(X, Y,*,\n",
    "                                test_frac = 0.10, validation_frac = 0.09, \n",
    "                                random_state = None, shuffle = True, stratify = None):\n",
    "    \n",
    "    X_aux, X_test, Y_aux, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=test_frac, random_state = random_state, shuffle = shuffle, stratify = stratify)\n",
    "    if validation_frac == 0:\n",
    "        return X_aux, X_test, Y_aux, Y_test\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_aux, Y_aux,\n",
    "                                                        test_size=validation_frac/(1 - test_frac), random_state = random_state, shuffle = shuffle, stratify = stratify)\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(data.index)\n",
    "N = 100000 # number of repeats for hypothesis tests\n",
    "\n",
    "count_by_id = data.groupby('id').size()\n",
    "X, Y = np.array(count_by_id.index), np.array(count_by_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Mike's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MV_Prediction/experiments/dispatcher.py lines 31-39'''\n",
    "def random_id_subset(ids, pc=0.1):\n",
    "    unique_id = np.unique(ids)\n",
    "    N_unique = len(unique_id)\n",
    "    np.random.shuffle(unique_id)\n",
    "    in_test = int(N_unique * pc)\n",
    "    test_ids = unique_id[:in_test]\n",
    "    test_mask = np.in1d(ids, test_ids)\n",
    "    train_mask = np.invert(test_mask)\n",
    "    return train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82136512 0.09261713 0.08601775]\n",
      " [0.81650599 0.09698113 0.08651288]\n",
      " [0.81260073 0.09789373 0.08950554]\n",
      " ...\n",
      " [0.79931215 0.10324314 0.09744471]\n",
      " [0.82890381 0.09372634 0.07736986]\n",
      " [0.79873692 0.10423341 0.09702967]]\n"
     ]
    }
   ],
   "source": [
    "''' from MV_Prediction/experiments/dispatcher.py'''\n",
    "ids = X.copy()\n",
    "N_runs = 100000                                               # L97 (adaptated)\n",
    "shuffle_seed = 500                                              # L80\n",
    "np.random.seed(shuffle_seed)                                    # L98\n",
    "splits = [random_id_subset(ids) for _ in range(N_runs)]         # L99 (adapted)\n",
    "total_data_size = count_by_id.sum()\n",
    "\n",
    "OM_train_test_val_proportions = []\n",
    "\n",
    "for (train_mask, test_mask) in splits:                                # L101 (adapted)\n",
    "    test_ids = ids[test_mask]                                         # L103 (adapted)\n",
    "    train_ids = ids[train_mask] # auxillary set                       # L106 (adapted)\n",
    "\n",
    "    train_mask, valid_mask = random_id_subset(train_ids, pc=0.1)      # L48 (adapted)\n",
    "    new_train_ids = train_ids[train_mask]\n",
    "    valid_ids = train_ids[valid_mask]\n",
    "    \n",
    "    # get the proportion of each set\n",
    "    train_size = (count_by_id[new_train_ids]).sum()\n",
    "    test_size = (count_by_id[test_ids]).sum()\n",
    "    validation_size = (count_by_id[valid_ids]).sum()\n",
    "\n",
    "    OM_train_test_val_proportions.append([(count_by_id[new_train_ids]).sum(), (count_by_id[test_ids]).sum(),(count_by_id[valid_ids]).sum()])\n",
    "\n",
    "\n",
    "OM_train_test_val_proportions = np.array(OM_train_test_val_proportions)/total_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting in the amount of data in each training, testing, and validation set differing from nominal values by at most 20 observations\n"
     ]
    }
   ],
   "source": [
    "delta = 0.00005\n",
    "\n",
    "print(f\"Resulting in the amount of data in each training, testing, and validation set differing from nominal values by at most {int(np.floor(delta*number_of_samples))} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to training, mu - 0.81 > -5e-05\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to training, mu - 0.81 >= 5e-05\n",
      "\n",
      " p-value for Test 2: 0.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for training data\n",
    "\n",
    "popmean = 0.81\n",
    "train_test_val_flag = 0 # training set\n",
    "\n",
    "TOST(OM_train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to testing, mu - 0.1 <= -5e-05\n",
      "\n",
      " p-value for Test 1: 0.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to testing, mu - 0.1 < 5e-05\n",
      "\n",
      " p-value for Test 2: 1.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for testing data\n",
    "\n",
    "popmean = 0.10\n",
    "train_test_val_flag = 1 # testing set\n",
    "\n",
    "TOST(OM_train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to validation, mu - 0.09 <= -5e-05\n",
      "\n",
      " p-value for Test 1: 0.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to validation, mu - 0.09 < 5e-05\n",
      "\n",
      " p-value for Test 2: 1.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for validation data\n",
    "\n",
    "popmean = 0.09\n",
    "train_test_val_flag = 2 # validation set\n",
    "\n",
    "TOST(OM_train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction interval (train proportions): (79.042, 83.069)\n",
      "\n",
      "Prediction interval (test proportions): (8.439, 11.517)\n",
      "\n",
      "Prediction interval (validation proportions): (7.5, 10.434)\n"
     ]
    }
   ],
   "source": [
    "set_type = ['train', 'test', 'validation']\n",
    "\n",
    "for ii,name in enumerate(set_type):\n",
    "    print(f\"\\nPrediction interval ({name} proportions): {prediction_interval(OM_train_test_val_proportions[:,ii], future_sample_size=1, alpha=0.05)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split drifter IDs into 81-10-9 and calculate the proportion of data in each of the sets\n",
    "\n",
    "train_test_val_proportions = []\n",
    "\n",
    "for ii in range(N):\n",
    "    _,_,_,Y_train,Y_test,Y_val = train_test_validation_split(X, Y,\n",
    "                                                             test_frac = 0.10, validation_frac = 0.09)\n",
    "    train_test_val_proportions.append([sum(Y_train),sum(Y_test),sum(Y_val)])\n",
    "\n",
    "train_test_val_proportions = np.array(train_test_val_proportions)/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "With the proportions of data in training, testing, and cross validations set calculated above for `N=100000` repetitions, we will test the following hypotheses:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two One-Sided Student's $t$-Tests (TOST)\n",
    "\n",
    "Since we are working within an application, if the training, testing, validation split differs very slightly from 81-10-9, the impact of this will be negligible in practice so we will allow for the mean proportion to differ from 0.81 up to $\\delta = 5\\times 10^{-5}$. Since the sample means of the training, testing, validation data proportion approximately follow normal distributions, respectively (CLT) and each combination of training, testing, and validation sets is independent, we can use the two-sided Student's $t$-test.\n",
    "\n",
    "Test 1\n",
    "\n",
    "$H_0^{(1)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 \\leq \\delta$.\n",
    "\n",
    "$H_1^{(1)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 > \\delta$.\n",
    "\n",
    "Test 2\n",
    "\n",
    "$H_0^{(2)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 \\geq \\delta$.\n",
    "\n",
    "$H_1^{(2)}$: The mean proportion of the data assigned to training, $\\mu - 0.81 < \\delta$.\n",
    "\n",
    "Significance Level: 5%\n",
    "\n",
    "and similarly for the proportion of the data assigned to the testing and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to training, mu - 0.81 <= -5e-05\n",
      "\n",
      " p-value for Test 1: 0.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to training, mu - 0.81 < 5e-05\n",
      "\n",
      " p-value for Test 2: 1.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for training data\n",
    "\n",
    "popmean = 0.81\n",
    "train_test_val_flag = 0 # training set\n",
    "\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to testing, mu - 0.1 > -5e-05\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to testing, mu - 0.1 >= 5e-05\n",
      "\n",
      " p-value for Test 2: 0.000\n"
     ]
    }
   ],
   "source": [
    "# TOST for testing data\n",
    "\n",
    "popmean = 0.10\n",
    "train_test_val_flag = 1 # testing set\n",
    "\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------- Test 1 -------------\n",
      "\n",
      "Fail to reject H0: The mean proportion of the data assigned to validation, mu - 0.09 > -5e-05\n",
      "\n",
      " p-value for Test 1: 1.000\n",
      "\n",
      " ------------- Test 2 -------------\n",
      "\n",
      "Reject H0: The mean proportion of the data assigned to validation, mu - 0.09 >= 5e-05\n",
      "\n",
      " p-value for Test 2: 0.007\n"
     ]
    }
   ],
   "source": [
    "# TOST for validation data\n",
    "\n",
    "popmean = 0.09\n",
    "train_test_val_flag = 2 # validation set\n",
    "\n",
    "TOST(train_test_val_proportions,train_test_val_flag,delta,popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction interval (train proportions): (78.961, 82.979)\n",
      "\n",
      "Prediction interval (test proportions): (8.48, 11.56)\n",
      "\n",
      "Prediction interval (validation proportions): (7.537, 10.482)\n"
     ]
    }
   ],
   "source": [
    "set_type = ['train', 'test', 'validation']\n",
    "\n",
    "for ii,name in enumerate(set_type):\n",
    "    print(f\"\\nPrediction interval ({name} proportions): {prediction_interval(train_test_val_proportions[:,ii], future_sample_size=1, alpha=0.05)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "1. Whether the proportion of the overall data contained within the training, testing, and validation sets are practically equal to the nominal nominal 81-10-9 proportions.\n",
    "\n",
    "The TOST analysis above shows that cluster sampling the drifter data by ID according to a training, testing, validation data split of 81-10-9, on average, leads to a training, testing, and validation datasets that form within \n",
    "\n",
    "* $(80.05 \\leq \\_ < 81.05)\\%$, \n",
    "* $(9.05 \\leq \\_ < 10.05)\\%$, \n",
    "* $(8.05 < \\_ < 9.05)\\%$ \n",
    "\n",
    "of the total drifter dataset, respectively at the 5% significance level.\n",
    "\n",
    "2. The nominal proportion of the overall dataset for all three data set types are found in their respective 95% prediction intervals. However, individual variability between the number of observations in each drifter ID cluster results in wide prediction intervals, thus for each train-test-validation split, there may be notable variability from the nominal values.\n",
    "\n",
    "The 95% prediction intervals (the intervals in which the proportion of the overall data each set will contain 95% of the time) are:\n",
    "\n",
    "|Data subset| Nominal Proportion| 95% Prediction Interval|\n",
    "|---|---|---|\n",
    "|Training |81\\%| $(79.0, 83.0)\\%$|\n",
    "|Testing| $10\\%$ | $(8.5, 11.6)\\%$|\n",
    "|Validation| $9\\%$| $(7.5, 10.5)\\%$|\n",
    "\n",
    "There is not very much uncertainty in the mean (TOST). Individual variability is where the potential problem lies (Prediction Intervals).\n",
    "\n",
    "It's up to my discretion as to whether this is a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding a seed that gives similar values to the nominal ones\n",
    "\n",
    "def nominal_cluster_sampling(data,*,\n",
    "                             test_frac = 0.10, validation_frac = 0.09, \n",
    "                             tol = 5e-5):\n",
    "    jj = 0\n",
    "\n",
    "    number_of_samples = len(data.index)\n",
    "    count_by_id = data.groupby('id').size()\n",
    "    X, Y = np.array(count_by_id.index), np.array(count_by_id)\n",
    "    train_frac = 1-test_frac-validation_frac\n",
    "\n",
    "    actual_test_frac = 0.0\n",
    "    actual_train_frac = 0.0\n",
    "    actual_validation_frac = 0.0\n",
    "    \n",
    "    while (np.abs(\n",
    "        np.array([actual_test_frac - test_frac\n",
    "                           , actual_train_frac -train_frac, \n",
    "                           actual_validation_frac - validation_frac])) > tol).any():\n",
    "        \n",
    "        seed = np.random.seed(jj)\n",
    "        \n",
    "        _,_,_,Y_train,Y_test,Y_val = train_test_validation_split(X, Y,\n",
    "                                                                    test_frac = test_frac, validation_frac = validation_frac, random_state=seed)\n",
    "        actual_train_frac, actual_test_frac, actual_validation_frac = np.array([sum(Y_train),sum(Y_test),sum(Y_val)])/number_of_samples\n",
    "\n",
    "        jj += 1\n",
    "    \n",
    "    print(np.abs(\n",
    "        np.array([actual_test_frac - test_frac\n",
    "                           , actual_train_frac -train_frac, \n",
    "                           actual_validation_frac - validation_frac])))\n",
    "    return(jj-1, Y_train, Y_test, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.22312188e-06 3.76691715e-05 2.84460496e-05]\n"
     ]
    }
   ],
   "source": [
    "seed, Y_train, Y_test, Y_train = nominal_cluster_sampling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63012\n"
     ]
    }
   ],
   "source": [
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,Y_train,Y_test,Y_val = train_test_validation_split(X, Y,\n",
    "                                                                    test_frac = 0.1, validation_frac = 0.09, random_state=np.random.seed(seed))\n",
    "actual_train_frac, actual_test_frac, actual_validation_frac = np.array([sum(Y_train),sum(Y_test),sum(Y_val)])/number_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81003767 0.09999078 0.08997155]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([sum(Y_train),sum(Y_test),sum(Y_val)])/number_of_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
